# ğŸ›ï¸ Ecommerce Catalog Scraper â€“ 6PM

AplicaciÃ³n web diseÃ±ada para automatizar el scraping de productos desde el ecommerce **6pm.com**, generando archivos CSV compatibles con **Shopify** de forma rÃ¡pida y eficiente.

---

## ğŸš€ CaracterÃ­sticas principales

- ğŸ” Scraping especializado para productos de 6PM.
- ğŸ“¦ GeneraciÃ³n de archivos CSV listos para importar a Shopify.
- âš™ï¸ AnÃ¡lisis del HTML utilizando `axios` y `node-html-parser`.
- ğŸ” AutenticaciÃ³n con JWT.
- ğŸ“ Almacenamiento de resultados en MongoDB.
- ğŸ§  Altamente optimizada: puede recolectar **14,000 productos en 11 minutos**.
- ğŸ’» Interfaz web moderna con React.
- ğŸ”„ Scroll infinito para navegaciÃ³n de archivos generados.

---

## ğŸ§° TecnologÃ­as utilizadas

- **Backend**: Node.js, Express, MongoDB, JWT.
- **Frontend**: React, Context API, React Router.
- **LibrerÃ­as clave**:
  - `axios`
  - `node-html-parser`
  - `json2csv`
  - `sonner` (notificaciones)
  - `p-limit` (control de concurrencia)

---

## âš™ï¸ Funcionalidad general

1. El usuario inicia sesiÃ³n mediante una interfaz protegida.
2. El sistema permite ingresar una URL de listado de productos de 6PM.
3. Se extraen los enlaces de productos y se procesan de forma concurrente.
4. La informaciÃ³n relevante (nombre, marca, SKU, imÃ¡genes, precio, descripciÃ³n, stock, etc.) se analiza y almacena.
5. Se genera un archivo CSV compatible con la estructura de importaciÃ³n de Shopify.
6. Los archivos se listan en el frontend con scroll infinito y pueden ser descargados.

---

## ğŸ“„ Requisitos para usar

- ConexiÃ³n a internet estable.
- Node.js 18 o superior.
- MongoDB en ejecuciÃ³n (local o remoto).
- Cuenta vÃ¡lida (sistema de login implementado).

